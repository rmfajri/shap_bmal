{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection,naive_bayes,svm\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "import re\n",
    "from utils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from math import log\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"dataset/Founta_edit/train.csv\")\n",
    "test=pd.read_csv(\"dataset/Founta_edit/test.csv\")\n",
    "unlabel=pd.read_csv(\"dataset/Founta_edit/unlabel.csv\")\n",
    "gold_standard=pd.read_csv(\"dataset/Founta_edit/gold_standard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_standard))\n",
    "print(len(gold_standard[gold_standard['label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter setting\n",
    "C = 1\n",
    "max_iter = 1000\n",
    "Degree=3\n",
    "Gamma='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2373\n",
      "2373\n",
      "7117\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "unlabel.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4773408230832845\n"
     ]
    }
   ],
   "source": [
    "#first training on train data\n",
    "X_train=train['text']\n",
    "y_train=train['label']\n",
    "X_test=test['text']\n",
    "y_test=test['label']\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(train['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(X_test)\n",
    "SVM = svm.SVC(C=1, kernel='linear', gamma='auto',probability=True)\n",
    "SVM.fit(Train_X_Tfidf,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "score=geometric_mean_score(y_test, predictions_SVM)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839\n",
      "2371\n",
      "6632\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction and predict on unlabel\n"
     ]
    }
   ],
   "source": [
    "#training a model and predict unlabel\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(train['text'])\n",
    "x_train = Tfidf_vect.transform(train['text']).toarray()\n",
    "x_test = Tfidf_vect.transform(test['text']).toarray()\n",
    "x_pool=Tfidf_vect.transform(unlabel['text']).toarray()\n",
    "y_train=train['label']\n",
    "print(\"model prediction and predict on unlabel\")\n",
    "model = SVC( max_iter=max_iter, C=C, kernel='linear',probability=True,gamma=Gamma,degree=Degree)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train,y_train)\n",
    "prediction=model.predict(x_pool)\n",
    "probs=model.predict_proba(x_pool)\n",
    "entropy=list()\n",
    "for p in probs:\n",
    "    ent=0\n",
    "    ent1=-p[0] * log(p[0],2)\n",
    "    ent2=-p[1] * log(p[1],2)\n",
    "    ent=ent1+ent2\n",
    "    entropy.append(ent)\n",
    "df=pd.DataFrame({'index':unlabel['index'],\"text\":unlabel['text'],\"confidence\":entropy,'prediction':prediction})\n",
    "df=df.sort_values(by=\"confidence\",ascending=False)\n",
    "#unlabel_length=len(unlabel)*0.1\n",
    "#taking the whole unlabel space\n",
    "unlabel_length=len(unlabel)\n",
    "low_conf=df[0:round(unlabel_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6632"
      ]
     },
     "execution_count": 1329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate Shapley value \n",
      "clusterint \n"
     ]
    }
   ],
   "source": [
    "#calculate shapley value on low conf data\n",
    "x_pool=Tfidf_vect.transform(low_conf['text']).toarray()\n",
    "print(\"calculate Shapley value \")\n",
    "explainer = shap.LinearExplainer(model, x_train,feature_dependence=\"independent\")\n",
    "shap_values_train = explainer.shap_values(x_train)\n",
    "shap_values_pool = explainer.shap_values(x_pool)\n",
    "n_clusters=20\n",
    "\n",
    "print(\"clusterint \")\n",
    "kmeans = KMeans(n_clusters= n_clusters, n_jobs=-1, max_iter=600)\n",
    "kmeans.fit(shap_values_pool)\n",
    "\n",
    "#calculate the center\n",
    "similarity_to_center = list()\n",
    "similarity=0\n",
    "for i, instance in enumerate(shap_values_pool):\n",
    "    cluster_label = kmeans.labels_[i] # cluster of this instance\n",
    "    centroid = kmeans.cluster_centers_[cluster_label] # cluster center of the cluster of that instance\n",
    "    #similarity = 1-cosine(instance, centroid) # 1- cosine distance gives similarity\n",
    "    similarity = (1)-(distance.cosine([instance], [centroid]))\n",
    "    similarity_to_center.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=pd.DataFrame({\"index\":low_conf['index'],\"text\":low_conf['text'],'cluster':kmeans.labels_,\n",
    "                            'uncertainty':low_conf['confidence'],'similarity':similarity_to_center,\n",
    "                            'prediction':low_conf['prediction']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict=dict()\n",
    "n_cluster=20\n",
    "#creating the dataframe for each cluster\n",
    "for item in range(0,n_cluster):\n",
    "    cluster_dict['cluster_{0}'.format(item)]=cluster_labels[cluster_labels['cluster']==item] \n",
    "#Create the dataframe for each cluster\n",
    "for i in range(0,n_cluster):\n",
    "    globals()['cluster_{}'.format(i)] = pd.DataFrame(cluster_dict['cluster_{}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    globals()['cluster_{}'.format(i)]=globals()['cluster_{}'.format(i)].sort_values(by=\"similarity\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "33\n",
      "163\n",
      "74\n",
      "5297\n",
      "51\n",
      "96\n",
      "44\n",
      "51\n",
      "19\n",
      "206\n",
      "91\n",
      "124\n",
      "60\n",
      "40\n",
      "3\n",
      "36\n",
      "178\n",
      "7\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(len(globals()['cluster_{}'.format(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples 29\n",
      "max sim 0.9320539684480873\n",
      "min sim 0.45648320814581944\n",
      "range  0.47557076030226786\n"
     ]
    }
   ],
   "source": [
    "clus_name=globals()['cluster_19']\n",
    "print(\"#samples\",len(clus_name))\n",
    "print(\"max sim\",clus_name['similarity'].max())\n",
    "print(\"min sim\",clus_name['similarity'].min())\n",
    "print(\"range \",(clus_name['similarity'].max()-clus_name['similarity'].min()))\n",
    "\n",
    "#print(\"========Uncertainty==============\")\n",
    "#print(\"max unc\",clus_name['uncertainty'].max())\n",
    "#print(\"min sim\",clus_name['uncertainty'].min())\n",
    "#print(\"range \",(clus_name['uncertainty'].max()-clus_name['uncertainty'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label for the cluster\n",
    "true_label=pd.read_csv(\"dataset/Founta_edit/gold_standard.csv\")\n",
    "#get the label\n",
    "new_train=true_label.merge(clus_name,on='index',how='left')\n",
    "new_train=new_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.drop(['text_y'],axis=1,inplace=True)\n",
    "new_train.rename(columns={\"text_x\": \"text\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train=new_train.sort_values(by='similarity',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class found 29\n",
      "minority class found 0\n",
      "percentage 0.0\n",
      "4844    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "l_minority=len(new_train[new_train['label']==1])\n",
    "l_majority=len(new_train[new_train['label']==0])\n",
    "total_samples=len(new_train)\n",
    "print(\"majority class found {}\".format(l_majority))\n",
    "print(\"minority class found {}\".format(l_minority))\n",
    "\n",
    "#percentage of minority\n",
    "print(\"percentage {}\".format(l_minority/total_samples))\n",
    "center_label=new_train['label'].head(1)\n",
    "print(center_label)\n",
    "\n",
    "new_train=new_train[['index','label','prediction','text','cluster','uncertainty','similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=new_train['label']\n",
    "pred=new_train['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(\"cluster_exploration/iteration_8/cluster_19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ground_truth,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>25776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>let talk ways wic helps mothers young children...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.304664</td>\n",
       "      <td>0.955785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>74269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>barry manilow surgery well ordered talk sing b...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.433939</td>\n",
       "      <td>0.953358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>57842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>iota omega hosts book talk community black pai...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.358882</td>\n",
       "      <td>0.949680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>35595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>enjoyable informative chat inspiring tedx talk...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.750224</td>\n",
       "      <td>0.934344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7033</th>\n",
       "      <td>71031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chance go exercise awhile nice bath talk someo...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.535303</td>\n",
       "      <td>0.934009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>63917</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk rest world proudly thank sir forgetting</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.606632</td>\n",
       "      <td>0.928588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>42237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>care spoken text bebecause need advice friend ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>0.904956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>15747</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>starting pm tomorrow lunchtime talk focus stub...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.224994</td>\n",
       "      <td>0.903342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>41751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>giving video benefit wouldoubt talk proof evid...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.213173</td>\n",
       "      <td>0.897528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>41660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idea asking talk somebody india talk someone</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>0.894509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>13354</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk wishing friday friday vat returns trip wo...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.330399</td>\n",
       "      <td>0.885544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>55036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>think rehearsal tweeting talk ask abt get</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.555021</td>\n",
       "      <td>0.870237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>74136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>really enjoyed giving talk llkd thanks audienc...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.429842</td>\n",
       "      <td>0.867281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>16234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uk rappers talk fighting demons talking chasin...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.286615</td>\n",
       "      <td>0.865711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>67280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hi wes could tell us babe lucca boy girl alway...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.258992</td>\n",
       "      <td>0.865583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>44730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>timbers com gt gt talk timbers alvas powell te...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.253652</td>\n",
       "      <td>0.863674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>42204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>getting ready talk packed house candidate foru...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.372185</td>\n",
       "      <td>0.851538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>35880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>girl works people owen talk loud guy heard</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.842664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6659</th>\n",
       "      <td>51705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>give us stitch proof russia gladly talk</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.220166</td>\n",
       "      <td>0.828265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>38842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>girls literally try talk bad ex literally blow...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.178616</td>\n",
       "      <td>0.823932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>70314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>walked n semo mtg n time hear tv show survivor...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.429767</td>\n",
       "      <td>0.816065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>32348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>events coordinator cc cannot kids secret talk</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.551304</td>\n",
       "      <td>0.815479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>38648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>magic timing events like action inaction conse...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>0.809744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>25789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tonight talk captain fehringer missing lnk wom...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.334640</td>\n",
       "      <td>0.788163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>26272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thoughts revisit make nate listen talk taxatio...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.386725</td>\n",
       "      <td>0.777120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>29257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>interviews educated underachieving liberal doc...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.480729</td>\n",
       "      <td>0.776731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>54310</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>guys talk trump assassinated tv show homeland ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.478511</td>\n",
       "      <td>0.770459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>60647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talking bebecause lonely rt tyson wanna hear talk</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.837101</td>\n",
       "      <td>0.747313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>41735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk misa night moon light good like wanna see...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.395505</td>\n",
       "      <td>0.738724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>48621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>birthday april th would happy talk direct mess...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.140273</td>\n",
       "      <td>0.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>41882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flirt call crush bro call things neat talk thr...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.345829</td>\n",
       "      <td>0.718397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>32685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk babies dying psychiatry killing humanrigh...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.345742</td>\n",
       "      <td>0.711720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>57768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>someone think annoying talk lot interesting li...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.492819</td>\n",
       "      <td>0.704635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>54515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ok bananas ew last person talk sleep special</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.163669</td>\n",
       "      <td>0.658334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>83976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nasty twitter bout none shit</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.810833</td>\n",
       "      <td>0.588701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>32535</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>u cannot talk relationship must nice u brag ma...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.953334</td>\n",
       "      <td>0.569406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  label  prediction  \\\n",
       "3303  25776      0         0.0   \n",
       "1400  74269      0         0.0   \n",
       "427   57842      0         0.0   \n",
       "2294  35595      0         0.0   \n",
       "7033  71031      0         0.0   \n",
       "6956  63917      0         0.0   \n",
       "3535  42237      0         0.0   \n",
       "4304  15747      0         0.0   \n",
       "2957  41751      0         0.0   \n",
       "571   41660      0         0.0   \n",
       "7024  13354      0         0.0   \n",
       "1529  55036      0         0.0   \n",
       "364   74136      0         0.0   \n",
       "5573  16234      0         0.0   \n",
       "3639  67280      0         0.0   \n",
       "6689  44730      0         0.0   \n",
       "6902  42204      0         0.0   \n",
       "1530  35880      0         0.0   \n",
       "6659  51705      0         0.0   \n",
       "2355  38842      0         0.0   \n",
       "2025  70314      0         0.0   \n",
       "1983  32348      0         0.0   \n",
       "896   38648      0         0.0   \n",
       "4437  25789      0         0.0   \n",
       "1236  26272      0         0.0   \n",
       "3523  29257      0         0.0   \n",
       "921   54310      1         0.0   \n",
       "4233  60647      0         0.0   \n",
       "5725  41735      0         0.0   \n",
       "2685  48621      0         0.0   \n",
       "4149  41882      0         0.0   \n",
       "6920  32685      0         0.0   \n",
       "1616  57768      0         0.0   \n",
       "2035  54515      0         0.0   \n",
       "2143  83976      0         0.0   \n",
       "2479  32535      1         0.0   \n",
       "\n",
       "                                                   text  cluster  uncertainty  \\\n",
       "3303  let talk ways wic helps mothers young children...     16.0     0.304664   \n",
       "1400  barry manilow surgery well ordered talk sing b...     16.0     0.433939   \n",
       "427   iota omega hosts book talk community black pai...     16.0     0.358882   \n",
       "2294  enjoyable informative chat inspiring tedx talk...     16.0     0.750224   \n",
       "7033  chance go exercise awhile nice bath talk someo...     16.0     0.535303   \n",
       "6956       talk rest world proudly thank sir forgetting     16.0     0.606632   \n",
       "3535  care spoken text bebecause need advice friend ...     16.0     0.395130   \n",
       "4304  starting pm tomorrow lunchtime talk focus stub...     16.0     0.224994   \n",
       "2957  giving video benefit wouldoubt talk proof evid...     16.0     0.213173   \n",
       "571        idea asking talk somebody india talk someone     16.0     0.386819   \n",
       "7024  talk wishing friday friday vat returns trip wo...     16.0     0.330399   \n",
       "1529          think rehearsal tweeting talk ask abt get     16.0     0.555021   \n",
       "364   really enjoyed giving talk llkd thanks audienc...     16.0     0.429842   \n",
       "5573  uk rappers talk fighting demons talking chasin...     16.0     0.286615   \n",
       "3639  hi wes could tell us babe lucca boy girl alway...     16.0     0.258992   \n",
       "6689  timbers com gt gt talk timbers alvas powell te...     16.0     0.253652   \n",
       "6902  getting ready talk packed house candidate foru...     16.0     0.372185   \n",
       "1530         girl works people owen talk loud guy heard     16.0     0.431362   \n",
       "6659            give us stitch proof russia gladly talk     16.0     0.220166   \n",
       "2355  girls literally try talk bad ex literally blow...     16.0     0.178616   \n",
       "2025  walked n semo mtg n time hear tv show survivor...     16.0     0.429767   \n",
       "1983      events coordinator cc cannot kids secret talk     16.0     0.551304   \n",
       "896   magic timing events like action inaction conse...     16.0     0.194987   \n",
       "4437  tonight talk captain fehringer missing lnk wom...     16.0     0.334640   \n",
       "1236  thoughts revisit make nate listen talk taxatio...     16.0     0.386725   \n",
       "3523  interviews educated underachieving liberal doc...     16.0     0.480729   \n",
       "921   guys talk trump assassinated tv show homeland ...     16.0     0.478511   \n",
       "4233  talking bebecause lonely rt tyson wanna hear talk     16.0     0.837101   \n",
       "5725  talk misa night moon light good like wanna see...     16.0     0.395505   \n",
       "2685  birthday april th would happy talk direct mess...     16.0     0.140273   \n",
       "4149  flirt call crush bro call things neat talk thr...     16.0     0.345829   \n",
       "6920  talk babies dying psychiatry killing humanrigh...     16.0     0.345742   \n",
       "1616  someone think annoying talk lot interesting li...     16.0     0.492819   \n",
       "2035       ok bananas ew last person talk sleep special     16.0     0.163669   \n",
       "2143                  talk nasty twitter bout none shit     16.0     0.810833   \n",
       "2479  u cannot talk relationship must nice u brag ma...     16.0     0.953334   \n",
       "\n",
       "      similarity  \n",
       "3303    0.955785  \n",
       "1400    0.953358  \n",
       "427     0.949680  \n",
       "2294    0.934344  \n",
       "7033    0.934009  \n",
       "6956    0.928588  \n",
       "3535    0.904956  \n",
       "4304    0.903342  \n",
       "2957    0.897528  \n",
       "571     0.894509  \n",
       "7024    0.885544  \n",
       "1529    0.870237  \n",
       "364     0.867281  \n",
       "5573    0.865711  \n",
       "3639    0.865583  \n",
       "6689    0.863674  \n",
       "6902    0.851538  \n",
       "1530    0.842664  \n",
       "6659    0.828265  \n",
       "2355    0.823932  \n",
       "2025    0.816065  \n",
       "1983    0.815479  \n",
       "896     0.809744  \n",
       "4437    0.788163  \n",
       "1236    0.777120  \n",
       "3523    0.776731  \n",
       "921     0.770459  \n",
       "4233    0.747313  \n",
       "5725    0.738724  \n",
       "2685    0.720300  \n",
       "4149    0.718397  \n",
       "6920    0.711720  \n",
       "1616    0.704635  \n",
       "2035    0.658334  \n",
       "2143    0.588701  \n",
       "2479    0.569406  "
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_exclude=list()\n",
    "cluster_exclude=[1,4,8,15,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label propagation\n",
    "#read the ground truth\n",
    "search_idx=list()\n",
    "gold_standard=pd.read_csv(\"dataset/Founta_edit/gold_standard.csv\")\n",
    "for i in range(0,20):\n",
    "    if i in cluster_exclude:\n",
    "        continue\n",
    "    else:\n",
    "        #search for the label in the ground truth\n",
    "        search_index=globals()['cluster_{}'.format(i)]['index'].head(1).values[0]\n",
    "        labeled_selection=gold_standard.loc[gold_standard['index']==search_index]\n",
    "        labels=labeled_selection['label'].values[0]\n",
    "        globals()['cluster_{}'.format(i)]['label']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing \n",
      "1241\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#get the data and balance it before put back in the training dataset\n",
    "print(\"Balancing \")\n",
    "conf_data=pd.DataFrame()\n",
    "for i in range(0,20):\n",
    "    if i in cluster_exclude:\n",
    "        continue\n",
    "    else:\n",
    "        conf_data=conf_data.append(globals()['cluster_{}'.format(i)])\n",
    "print(len(conf_data[conf_data['label']==0]))\n",
    "print(len(conf_data[conf_data['label']==1]))\n",
    "majority=conf_data[conf_data['label']==0]\n",
    "n_minority_class=conf_data[conf_data['label']==1]\n",
    "if len(n_minority_class) > len(majority):\n",
    "    cluster_size=len(majority)\n",
    "elif len(n_minority_class)==0:\n",
    "    cluster_size=1\n",
    "else:\n",
    "    cluster_size=len(n_minority_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>similarity</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, text, cluster, uncertainty, similarity, prediction, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_data[conf_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the majority and cluster it based on number of minority class\n",
    "embeddings = Tfidf_vect.transform(majority['text'])\n",
    "#initialize the kmeans\n",
    "kmeans = KMeans(n_clusters=cluster_size, random_state=0,max_iter=600,n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "labels = (kmeans.labels_)\n",
    "#create the cluster for each low conf data\n",
    "cluster_labels = pd.DataFrame({'index':majority['index'],'cluster':labels,'text':majority['text'],\n",
    "                               'label':majority['label']})\n",
    "cluster_dict=dict()\n",
    "#creating the dataframe for each cluster\n",
    "for item in range(0,cluster_size):\n",
    "    cluster_dict['cluster_{0}'.format(item)]=cluster_labels[cluster_labels['cluster']==item] \n",
    "for i in range(0,cluster_size):\n",
    "        globals()['cluster_{}'.format(i)] = pd.DataFrame(cluster_dict['cluster_{}'.format(i)])\n",
    "center=kmeans.cluster_centers_\n",
    "#print(center.shape)\n",
    "#create the data frame of the cluster center\n",
    "centerpd=pd.DataFrame(center)\n",
    "#inverse transform the center to text\n",
    "inver=Tfidf_vect.inverse_transform(centerpd)\n",
    "#get the inverse word and create as a sentence\n",
    "sentence=[' '.join(item) for item in inver]\n",
    "#Calculate the data that close to the center for each cluster\n",
    "for i in range(0,cluster_size):\n",
    "    sent=list()\n",
    "    cossim=list()\n",
    "    for item in globals()['cluster_{}'.format(i)]['text']:\n",
    "        sent.append(item)\n",
    "    for k in sent:\n",
    "        vector1=text_to_vector(k)\n",
    "        vector2=text_to_vector(sentence[i])\n",
    "        cosine=get_cosine(vector1,vector2)\n",
    "        cossim.append(cosine)\n",
    "    globals()['cluster_{}'.format(i)]['similarity']=cossim\n",
    "    globals()['cluster_{}'.format(i)]=globals()['cluster_{}'.format(i)].sort_values(by='similarity',ascending=False)\n",
    "center_data=pd.DataFrame()\n",
    "for i in range(0,cluster_size):\n",
    "    center_data=center_data.append(globals()['cluster_{}'.format(i)].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839\n",
      "2371\n",
      "6632\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding to training data\n",
    "train_1=n_minority_class\n",
    "train_0=center_data\n",
    "new_train=pd.DataFrame()\n",
    "#adding the balanced set for training\n",
    "frames=[train_1,train_0] \n",
    "\n",
    "new_train=pd.concat(frames)\n",
    "new_train.drop(['cluster','similarity'],axis=1,inplace=True)\n",
    "training_data=pd.DataFrame({'index':new_train['index'],\n",
    "                           'label':new_train['label'],'text':new_train['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minorty class 0\n",
      "majority class 1\n"
     ]
    }
   ],
   "source": [
    "print(\"minorty class {}\".format(len(new_train[new_train['label']==1])))\n",
    "print(\"majority class {}\".format(len(new_train[new_train['label']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to training data and remove from unlabel pool\n",
    "minority_sum=len(new_train[new_train['label']==1])\n",
    "if minority_sum >= 0:\n",
    "    train=train.append(training_data)\n",
    "    train.to_csv(\"training/training.csv\",index=False)\n",
    "\n",
    "    test.to_csv(\"training/test.csv\",index=False)\n",
    "\n",
    "    unlabel=unlabel[~unlabel['index'].isin(train['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2840\n",
      "2371\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating performance\n",
    "train1=pd.read_csv(\"training/training.csv\")\n",
    "test1=pd.read_csv(\"training/test.csv\")\n",
    "\n",
    "train1.dropna(inplace=True)\n",
    "test1.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X_train=train1['text']\n",
    "y_train=train1['label']\n",
    "X_test=test1['text']\n",
    "y_test=test1['label']\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(train['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(X_test)\n",
    "SVM = svm.SVC(C=1, kernel='linear', gamma='auto',probability=True)\n",
    "SVM.fit(Train_X_Tfidf,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "score=geometric_mean_score(y_test, predictions_SVM)\n",
    "#gmean.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5892165596713536\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
